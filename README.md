#  Predicci贸n de Enfermedad Card铆aca: Un Enfoque Transparente y tico (XAI)

###  Resumen del Proyecto
Este proyecto implementa un modelo de Machine Learning (Random Forest) para predecir la presencia de enfermedades card铆acas utilizando el dataset **Heart Disease UCI** (combinado).

El objetivo central no es solo maximizar la precisi贸n, sino garantizar la **Calidad del Dato**, la **Transparencia (XAI)** y realizar una **Auditor铆a tica** rigurosa para detectar discriminaci贸n algor铆tmica antes de un hipot茅tico despliegue m茅dico.

---

## 1.  Gesti贸n de Calidad de Datos

Se utiliz贸 el dataset combinado que incluye 4 bases de datos (Cleveland, Hungr铆a, Suiza, Long Beach VA) con un total inicial de **920 registros**.

### 1.1 Auditor铆a y Limpieza Rigurosa
Durante la exploraci贸n de datos (EDA), detectamos un problema cr铆tico:
* **El Problema:** Las bases de datos de Hungr铆a, Suiza y Long Beach no registraron consistentemente variables vitales como `ca` (n煤mero de vasos mayores coloreados por fluoroscopia) y `thal` (tipo de talasemia). Estas columnas presentaban un **>60% de valores nulos**.
* **La Decisi贸n:** Priorizamos la **integridad cl铆nica** sobre el volumen de datos.
* **La Acci贸n:** Se aplic贸 un filtrado estricto (`dropna`), descartando los registros incompletos.
    * *Resultado:* El dataset se redujo a **299 pacientes** (principalmente del est谩ndar de oro de Cleveland).
    * *Justificaci贸n:* Imputar (inventar) datos complejos como una fluoroscopia o un defecto gen茅tico (talasemia) introducir铆a ruido inaceptable en un modelo de salud, alucinando explicaciones en la fase de XAI.

**Auditor铆a de Nulos (Antes de la limpieza):**
> ![Gr谩fico de barras de "Detecci贸n de Valores Nulos"](./img/valores-nulos.png)

---

## 2. 锔 Metodolog铆a y Pre-procesamiento

Para preparar los datos para el modelo Random Forest, aplicamos:

### A. Traducci贸n de Variables (Label Encoding)
El dataset conten铆a variables categ贸ricas en texto (ej: "Typical Angina", "Male"). Se codificaron num茅ricamente y se gener贸 un diccionario para mantener la interpretabilidad.

**Diccionario de Mapeo:**
> ![Inserte aqu铆 la captura de la tabla "DICCIONARIO DE CODIFICACIN"](./img/codificacion.png)

### B. Simplificaci贸n del Objetivo (Target Binarization)
La variable `num` original clasifica la enfermedad del 0 al 4.
* **Transformaci贸n:** Simplificamos el problema a **Clasificaci贸n Binaria**.
    * `0` = Sano
    * `1, 2, 3, 4` $\rightarrow$ **1 (Enfermo)**
* **Motivo:** Las clases severas (3 y 4) ten铆an muestras insuficientes, lo que hubiera impedido el aprendizaje del modelo.

**Distribuci贸n de Clases:**
> ![Gr谩ficos comparativos de distribuci贸n](./img/distribucion-datos.png)

---

## 3.  Entrenamiento del Modelo

* **Algoritmo:** Random Forest Classifier.
* **Configuraci贸n:** 100 谩rboles, profundidad m谩xima de 5 (para evitar sobreajuste).
* **M茅tricas Globales:** El modelo alcanz贸 una precisi贸n (Accuracy) del 85%, en el set de prueba depurado.

---

## 4.  Explicabilidad (XAI)

Para validar la l贸gica m茅dica del algoritmo, utilizamos dos t茅cnicas de Caja Blanca:

### T茅cnica 1: Permutation Feature Importance
Mide qu茅 tanto cae el rendimiento del modelo si eliminamos la informaci贸n de una variable.

**Variables M谩s Importantes:**
> ![Gr谩fico de Barras Horizontal](./img//permutation-importance.png)

* **Hallazgo:** El modelo depende fuertemente de `cp` (Dolor de pecho), `thal` (Talasemia) y `ca` (Vasos), lo cual coincide con la literatura cardiol贸gica.

### T茅cnica 2: SHAP (Global y Local)
Analiza el impacto positivo o negativo de cada s铆ntoma.

**Resumen Global (Beeswarm):**
> ![Gr谩fico de puntos de colores](./img/shap.png)

### Explicaci贸n de un Caso (Paciente #0)
Desglosamos la decisi贸n del modelo para el primer paciente del set de prueba.

**Gr谩fico Waterfall:**
> ![Inserte aqu铆 la captura del gr谩fico Waterfall](./img/xai-caso-individual.png)

* **Interpretaci贸n:** Podemos ver exactamente qu茅 s铆ntomas (barras rojas) empujaron al modelo a diagnosticar enfermedad y qu茅 factores protectores (barras azules) intentaron mitigar el riesgo.

---

## 5. 锔 Auditor铆a tica y Sesgos

Se evalu贸 el principio de **Justicia (Fairness)** comparando el rendimiento en **Hombres** vs **Mujeres**.

**Gr谩fico de Disparidad:**
> ![Inserte aqu铆 la captura del gr谩fico de barras "Sensibilidad por G茅nero"](./img/disparidad-rendimiento-por-genero.png)

###  Resultados Cr铆ticos:
Los datos revelaron un comportamiento inesperado en este experimento:
1.  **Sensibilidad en Mujeres (1.00):** El modelo detect贸 el **100%** de los casos de enfermedad en mujeres. No hubo falsos negativos.
2.  **Sensibilidad en Hombres (0.75):** El modelo fall贸 al detectar la enfermedad en el **25%** de los hombres enfermos.
3.  **Conclusi贸n del Sesgo:** Existe una brecha de rendimiento del 25% que penaliza a los hombres. En un entorno hospitalario, este modelo ser铆a peligroso para los pacientes masculinos, ya que 1 de cada 4 podr铆a ser enviado a casa err贸neamente sin tratamiento.

---

## 6.  Conclusiones y Recomendaciones

1.  **Calidad sobre Cantidad:** La decisi贸n de descartar el 60% de la data fue correcta para garantizar que las explicaciones (SHAP) se basaran en datos cl铆nicos reales y no imputados.
2.  **Transparencia:** Las herramientas XAI demostraron que el modelo "piensa" correctamente (usa las variables m茅dicas adecuadas), pero eso no garantiza que sea justo.
3.  **Recomendaci贸n de No-Despliegue:** A pesar de la buena precisi贸n global, **el modelo no debe pasar a producci贸n**.
    * La disparidad de sensibilidad contra los hombres es 茅ticamente inaceptable.
    * **Pr贸ximos pasos:** Se requiere recolectar m谩s datos masculinos de alta calidad o aplicar t茅cnicas de regularizaci贸n para equilibrar la sensibilidad entre g茅neros antes de su uso cl铆nico.

---